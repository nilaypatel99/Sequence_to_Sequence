{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "hlyesjCWLZha",
        "outputId": "e2eec44a-3178-40f2-fc99-b01071f3aeb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4mWhvHIsLh8D"
      },
      "outputs": [],
      "source": [
        "PATH_TO_DATA = \"/content/drive/My Drive/OneFourthLabCourse/RNNs/Encoder-Decoder/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IOI4rlrgxPI-"
      },
      "source": [
        "## Outline\n",
        "\n",
        "\n",
        "1. Data set and task\n",
        "2. Data processing XML files\n",
        "3. Why we need encoder decoder architecture\n",
        "4. Basic GRU based encoder decoder\n",
        "5. Adding attention\n",
        "6. Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1GqTjeV47m4B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KpuvHS0mxwCd"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eYrAa5laSptM"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "-a04ZKx7Sh-J",
        "outputId": "f122349e-3516-4e53-9fca-3e0ff2a6fcf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ]
        }
      ],
      "source": [
        "# storing all the alphabets of English and the pad char to a dictionary to create OHE representation later.\n",
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "cPSZsy1kXd9w",
        "outputId": "f036db04-889b-48bb-b381-5884d6ada679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ]
        }
      ],
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SSw1SMZmx9A3"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OcS6ByndOxrC"
      },
      "outputs": [],
      "source": [
        "# Funcitons used to do some pre-processing.\n",
        "# removing all non-alphabetic char in English as well as Hindi.\n",
        "\n",
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ob3F9Dh4PChB"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KGSeoMGg0FTy"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        '''Task : to read the xml file and store all the contents in a list.\n",
        "                  Then we will do some pre-processing of data to remove noise as well as delimeters. '''\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text) # clean English words.\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)# clean hindi words.\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array): # child function of get_batch() function.\n",
        "        '''Given an array , and batch size , this fucntion will return some samples from the array i.e can be HindiWords or EnglishWords etc. '''\n",
        "        end = self.shuffle_start_index + batch_size # what index till i want to go.\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words): # if we overflow the words array , we have to loop back.\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "colab_type": "code",
        "id": "-FCCi-SerZS-",
        "outputId": "66298e54-27ad-429f-8c1c-cc98f32c6426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ]
        }
      ],
      "source": [
        "train_data = TransliterationDataLoader(PATH_TO_DATA+'NEWS2012TrainingEnHi.xml')\n",
        "test_data = TransliterationDataLoader(PATH_TO_DATA+'NEWS2012-Testing-EnHi-1000.xml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7l-iaCVdx5Ez"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "colab_type": "code",
        "id": "IjY06ghEx76b",
        "outputId": "1c56af66-785b-481c-c9c8-7a64e530cac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "DIVYA - दिव्य\n",
            "FAYE - फे\n",
            "OF - ऑफ\n",
            "PITAMBAR - पिताम्बर\n",
            "MUSEUM - म्युज़ियम\n",
            "DELHI - डेल्ही\n",
            "BIOTECH - बायोटेक\n",
            "BUSH - बुश\n",
            "DIYA - दिया\n",
            "BHOPATKAR - भोपटकर\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "colab_type": "code",
        "id": "Rhq3KaJojv0D",
        "outputId": "ec068f86-3220-449e-f8ab-d4ecf9c85bae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['MURRAY',\n",
              "  'AZIZ',\n",
              "  'YURUPARI',\n",
              "  'PHOOL',\n",
              "  'HALL',\n",
              "  'AWARAGARDI',\n",
              "  'OF',\n",
              "  'ACHYUTA',\n",
              "  'AWARD',\n",
              "  'SANT'],\n",
              " ['मुर्रे',\n",
              "  'अज़ीज़',\n",
              "  'यूरूपरी',\n",
              "  'फूल',\n",
              "  'हॉल',\n",
              "  'आवारागर्दी',\n",
              "  'ऑफ',\n",
              "  'अच्युत',\n",
              "  'अवार्ड',\n",
              "  'संत'])"
            ]
          },
          "execution_count": 16,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.get_batch(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KpDP1_KYZIkv"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JE3at5C7Sy5F"
      },
      "outputs": [],
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "colab_type": "code",
        "id": "-yE3jToOrfzP",
        "outputId": "8b4519b4-995d-4854-ff69-7b9c40c554c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GERATPUR tensor([[[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "uMcDjIberhc3",
        "outputId": "218219ce-e5aa-4501-e2f2-6d717f481a7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "गेरतपुर 8\n"
          ]
        }
      ],
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GrC3tSnm4rUk"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D4OgdZ_DVVC5"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6w8ffT3w4lkK"
      },
      "outputs": [],
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder input', input.shape)\n",
        "            print('Encoder output', out.shape)\n",
        "            print('Encoder hidden', hidden.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device) # also can be variable i.e learned from data.\n",
        "        outputs = []\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder input', decoder_input.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "            \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "\n",
        "            # debug : \n",
        "            #print(out)\n",
        "            #print(out.view(1, -1))\n",
        "            #\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "\n",
        "            ''' Now we will do some pre-processing to make the out into a One-hot encoded vector to be \n",
        "                feed to the decoder in the next iteration.Since we can use the softmax layer o/p to pass\n",
        "                it as the input to the decoder , we are not doing that because we want to use a concept\n",
        "                called Teacher enforcing . Instead of the decoder o/p OHE vector we can actually\n",
        "                feed the ground truth as Input to the decoder , this will he to accelerate tranning. '''\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            #print(max_idx) # debug\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "                #print(max_idx) # debug\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_() # all the elements will be 0.\n",
        "            #print(one_hot) # debug\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "            #print(one_hot) # debug\n",
        "            \n",
        "            decoder_input = one_hot.detach() # don't pass gradient with this tensor.\n",
        "            #print(decoder_input) # debug\n",
        "            \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1juBlYMouWiu"
      },
      "outputs": [],
      "source": [
        "# unlike fully connceted or CNN model , we have to write an inference routine in case of sequence model.\n",
        "def infer(net, eng_word,shape,device ='cpu'):\n",
        "    # net.eval()\n",
        "    input_ = word_rep(eng_word,eng_alpha2index,device) # convert the name into one hot encoding.\n",
        "    outputs = net(input_,shape,device) # initilise the hidden layer.\n",
        "    \n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Cra9toTiOoPm"
      },
      "outputs": [],
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "colab_type": "code",
        "id": "v4zaJq2pOrM8",
        "outputId": "b4948450-c15d-460e-c7d4-50ca09fc06d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder output torch.Size([6, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ]
        }
      ],
      "source": [
        "out = infer(net, 'INDIA', 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "colab_type": "code",
        "id": "1_pdzBmQOsjO",
        "outputId": "6a73fc6b-99fb-44da-a49d-040387469f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ू\n",
            "torch.Size([1, 129]) ै\n",
            "torch.Size([1, 129]) ट\n",
            "torch.Size([1, 129]) ै\n",
            "torch.Size([1, 129]) ट\n",
            "torch.Size([1, 129]) ो\n",
            "torch.Size([1, 129]) ै\n",
            "torch.Size([1, 129]) ट\n",
            "torch.Size([1, 129]) ो\n",
            "torch.Size([1, 129]) ै\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n",
            "torch.Size([1, 129]) ऒ\n"
          ]
        }
      ],
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NEg49N9e7oTY"
      },
      "source": [
        "### Encoder-Decoder with Attention \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8z-1QDAz8F_d"
      },
      "outputs": [],
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0t2sVOyuh-d-"
      },
      "outputs": [],
      "source": [
        "# unlike fully connceted or CNN model , we have to write an inference routine in case of sequence model.\n",
        "def infer(net, eng_word,shape,device ='cpu'):\n",
        "    # net.eval()\n",
        "    input_ = word_rep(eng_word,eng_alpha2index,device) # convert the name into one hot encoding.\n",
        "    outputs = net(input_,shape,device) # initilise the hidden layer.\n",
        "    \n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PMD3zjdJO0Oj"
      },
      "outputs": [],
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "colab_type": "code",
        "id": "YoiQwbntO5UH",
        "outputId": "90fd7004-a0c9-40e7-ac39-89be54b239e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ]
        }
      ],
      "source": [
        "out = infer(net_attn, 'INDIA', 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "colab_type": "code",
        "id": "K9WSPgzlO6k8",
        "outputId": "5f04964b-140a-47ac-ca0d-da2156de2220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ष\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ३\n",
            "torch.Size([1, 129]) श\n"
          ]
        }
      ],
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cyE2tSnmAW6x"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H893cimDtTUE"
      },
      "source": [
        "### Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "m804jsH7AXSV"
      },
      "outputs": [],
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-eZaBxstWz9"
      },
      "source": [
        "### Training Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Rjto129ssrpr"
      },
      "outputs": [],
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TZY6RvqLtdX8"
      },
      "source": [
        "### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1oQ3ZIWvtjfN"
      },
      "outputs": [],
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "colab_type": "code",
        "id": "E6LjVKQfoVMU",
        "outputId": "634f19bb-f979-4762-f7b6-e8050302856a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 119 Loss 0.3415161967277527\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X98leV9//HXJwlJEAKiJMqvGKyIoojYCFjtptgq1ApaO4sos1v3wLYy3VanOF1nretq19nN6Tb8uv5Y1VKrtaPFH62ufItOgfgLRUQQlB9VSQSFoCQk+eyP+77DTTwn5yTkzjkneT8fjzzIfZ/7nHPdnJAP1/W5rs9l7o6IiEhninLdABERyX8KFiIikpGChYiIZKRgISIiGSlYiIhIRgoWIiKSkYKFiIhkpGAhIiIZKViIiEhGJbluQE8ZPny419TU5LoZIiIF5dlnn21w98pM1/WZYFFTU0NdXV2umyEiUlDM7M1srtMwlIiIZKRgISIiGSlYiIhIRgoWIiKSkYKFiIhkpGABbN+1l4sXPc323Xtz3RQRkbykYAHc/sR6Vr2xg9sfX5/rpoiI5KU+s86iO8bf+AhNLW3tx/es2Mw9KzZTVlLEultm5rBlIiL5pV/3LJZfexZnjd+/cLF8QBGzTx7J8uvO0tCUiEhMvw4WVUPKGXnoQADMoKmljYqyEqoqyjU0JSISk2iwMLMZZrbOzDaY2cIUj3/RzOrN7IXw689ij11uZuvDr8uTamNDYxMnjRqKO3xu8ijuW7mZmoVLuWfFZtyDoamahUsZf+MjSTVBRCTvJRYszKwYuBOYCUwALjGzCSku/am7nxx+3R0+9zDg74CpwBTg78xsWBLtXDSvln+6eBIAk8YcyjPXn83046raH48PTYmI9FdJ9iymABvcfaO7NwOLgdlZPvdc4DfuvsPddwK/AWYk1E7GHVHBuKrB/Gr1W1QNKefVt3e1P7Z3XxtPv/5uUm8tIlIQkgwWo4AtseOt4bmOLjKz1Wb2gJmN6eJze8x5J41g5aYdTP/uMn7/3l4mVx/K1LGHAbB9d5NyFyLSr+U6wf1LoMbdTyLoPfyoK082s/lmVmdmdfX19QfVkPMmjgBgY8MeBpcV88rvd7Fi0472x5W7EJH+LMl1FtuAMbHj0eG5du4eH9+5G/hO7Llndnjuso5v4O53AXcB1NbWencb2nG9RWNTKwBFBiVFRTS3tlFcZHz2pBHccN7x3X0bEZGClWTPYhUwzszGmlkpMAdYEr/AzEbEDmcBa8PvHwPOMbNhYWL7nPBcIpZfexazTh7JgGID9ie1L5g8in1tbRQbtLY5OxubWHDf81p7ISL9TmLBwt1bgAUEv+TXAve7+xozu9nMZoWXXWVma8zsReAq4Ivhc3cA3yQIOKuAm8NziagaUk5FWQktbU5ZSVH7eos9TS1cOvUofvaV0xhcVsxTr7/b6doLLeQTkb7K3Ls9epNXamtr/WC2Vb3ix3VUVpQzd0o1963cTP3uvSyaVwt8dJgq0rEsyI0PvcS9Kzdz4cmj2Preh9wxdzJVFeXdbpOISNLM7Fl3r814nYJFZtt37eWWh9eydPVbtLY5pcXGWcdVsX13E4vmfZxP3vrblMGkyGDjP5yXSJtERHpCtsEi17OhCkI0TNXmjgHNrc5rbzfywpb3uP3x9Sy/9izOPLbyI89rczSDSkT6hH5ddbYrGhqbuHTqUfx01Wb2tTqb3t0D7K9UGzEg6qsVGZw/aaRmUIlIwVPPIkuL5tVyywUn8tR10zl5zKHt58sHFDFr0ggGFBujhw1k5olHAkHQaHOo371XM6hEpOApWHRR1ZByThg5pP24qaWNxqZW9rU6N3zmeFrduWzaUfziytMZXFbMik07VL1WRAqehqG6oaGxiRknHMGja97huCMqWL6+nsFlxUw/voqZ4UpwbawkIn2JehbdsGheLf8xr5bzJo7gtXd2s6/VGTF0IGUlxe3XLL/2LGZNGklRsM6P8hJVrxWRwqWeRTd17Dms395IzcKl7T2HqiHlVJSXEM1M3hvbWElEpNCoZ9FNUYmQkqIDS4TEew4NjU1cOu0oTv/Y4ZQUwcaGRq3wFpGCpGDRTdHai1Y/sERIvOcQzaD6xuwTaHPYsWefkt0iUpA0DHUQorUX8RIhqZx3+5O0Obz69m5AyW4RKTwq99ELtu/ay9889BKPr90OBENW555wJDecd7xyGCKSUyr3kUeqhpRzxJD9QSHVkJWISD5TsOglDY1NnDk+qB/1B+OGU9/YlOMWiYhkTzmLXrJoXi0trW2cfuv/UGTWXv5cRKQQJNqzMLMZZrbOzDaY2cJOrrvIzNzMasPjAWb2IzN7yczWmtn1Sbazt5QUF/GF2jH8dl09F9z5pKbQikjBSCxYmFkxcCcwE5gAXGJmE1JcVwFcDayInf4joMzdJwIfB64ws5qk2tqbLj412Jb8hS3vawqtiBSMJIehpgAb3H0jgJktBmYDr3S47pvArcBfx845MMjMSoCBQDOwK8G29grVixKRQpXkMNQoYEvseGt4rp2ZnQKMcfelHZ77ALAHeAvYDHw3yT24e0u06ntAcbDqu0z1okSkQORsNpSZFQG3AV9L8fAUoBUYCYwFvmZmR6d4jflmVmdmdfX19Ym2tydEq75b2oK1LZpCKyKFIslgsQ0YEzseHZ6LVAAnAsvM7A1gGrAkTHLPBR51933uvh14CvjI9CF3v8vda929trLyo9ua5qNo1fek0UMZUl6iKbQiUhCSDBargHFmNtbMSoE5wJLoQXd/392Hu3uNu9cAzwCz3L2OYOhpOoCZDSIIJK8m2NZeE9WLunDyKHbtbeHaGcflukkiIhklFizcvQVYADwGrAXud/c1Znazmc3K8PQ7gcFmtoYg6PzA3Vcn1dZcOOeEYPvVX695J8ctERHJTLWhcuj8f30SxzmktIQ75k5W7kJEep1qQxWAc084gpe37VLZchHJeyr3kSPxNRfuWnMhIvlNPYscifboDrfoTrnTnohIvlCwyJH2PbrDY625EJF8pmCRQw2NTZx/0ggAao8apjUXIpK3lLPIoahM+Wvv/O6AYxGRfKOeRR747EkjWPXGTt56/8NcN0VEJCUFizzw2UkjAfjCoqe1x4WI5CUFizwwdvgghh0ygM07PtR6CxHJS8pZ5Jj2uBCRQqCeRY5Fe1yUlQQfRUmRab2FiOQdBYsci/a4aG5tw4CWNtd6CxHJOwoWeSDa4+JLZ4wF4M0dH+S4RSIiB1LOIg9E6yu27vyAu5/cxGkfOzzHLRIROZB6Fnlk9LBDmFx9KL94fhsXaxqtiOQRBYs8c97EEbz2TiOrNqlsuYjkj0SDhZnNMLN1ZrbBzBZ2ct1FZubh/tvRuZPM7GkzW2NmL5lZn8/4jr/xEW5ZuhYAJ5hGW7NwKeNvfCS3DRORfi+xYGFmxQTbo84EJgCXmNmEFNdVAFcDK2LnSoB7gC+7+wnAmcC+pNqaL6JptEVh3XKVLReRfJFkz2IKsMHdN7p7M7AYmJ3ium8CtwLxAfpzgNXu/iKAu7/r7q0JtjUvRNNoo51um/apbLmI5Ickg8UoYEvseGt4rp2ZnQKMcfelHZ57LOBm9piZPWdm16Z6AzObb2Z1ZlZXX1/fk23PmWAabTXHVg3mkNJi3tmtsuUikns5S3CbWRFwG/C1FA+XAGcAl4Z/XmhmZ3e8yN3vcvdad6+trKxMtL29ZdG8Wm65cCILP3Mce5pbmVpzmGZGiUjOJRkstgFjYsejw3ORCuBEYJmZvQFMA5aESe6twO/cvcHdPwAeBk5JsK1556zxVZw0eij//MRrrHpDM6NEJLeSXJS3ChhnZmMJgsQcYG70oLu/DwyPjs1sGXCNu9eZ2evAtWZ2CNAM/CHwvQTbmneO+9tHVWBQRPJGYj0Ld28BFgCPAWuB+919jZndbGazMjx3J8EQ1SrgBeC5FHmNPm35tWcxa9JIwolRmhklIjmVaLkPd3+YYAgpfu7raa49s8PxPQTTZ/ulqiHlVJSXEE6M0swoEckpreDOYw2NTVz08VEUGxw3ooL6Rs2MEpHcUCHBPBYVGPygqZX/fb2BwWUlbN+9V70LEel16lkUgEumVPP+hy3UvbFTs6JEJCfUs8hz8W1Xo3pRmhUlIr1NPYs8F9WLKgkLRpWVaFaUiPQ+BYs8F9WLam0L5kU1tWhWlIj0PgWLAtDQ2MSl045i0uihDC4r1qwoEel1ylkUgGhW1IPPbuVrP3uRL51xdI5bJCL9jXoWBWTmxCMZVFrMPU+/qeKCItKrFCwKyCGlJcycOIKHX35LxQVFpFdpGKqAxKfRgqbRikjvUc+igKi4oIjkioJFAYmKC0ZUXFBEeouCRYFpaGxi7tRqqocNZHBZMUtfekuJbhFJnIJFgVk0r5a/v3Ai1808nt1Nrbz3wT4lukUkcYkGCzObYWbrzGyDmS3s5LqLzMzDLVXj56vNrNHMrkmynYVm/I2PcOV9zwH760XVLFzK+BsfyW3DRKTPSixYmFkxcCcwE5gAXGJmE1JcVwFcDaxI8TK3AfoN2EFUL2pAcZDqHlBsSnSLSKKS7FlMATa4+0Z3bwYWA7NTXPdN4FbggIF3M7sA2ASsSbCNBSmqF9US1ova1+pKdItIopIMFqOALbHjreG5dmZ2CjCm4/7aZjYYuA74RoLtK2gNjU1cOvUo/uQTNQBsbNiT2waJSJ+Ws0V5ZlZEMMz0xRQP3wR8z90bzSzFw+2vMR+YD1BdXd3zjcxjUb2onXuauW/lZqoqyrl40dPcMXeyehgi0uOS7FlsA8bEjkeH5yIVwInAMjN7A5gGLAmT3FOB74Tn/wL4GzNb0PEN3P0ud69199rKyspk7iLPDRtUygUnj+KXL25TCRARSYy5ezIvbFYCvAacTRAkVgFz3T1lDsLMlgHXuHtdh/M3AY3u/t3O3q+2ttbr6uo6u6RP6lgCJKISICKSDTN71t1rM12XWM/C3VuABcBjwFrgfndfY2Y3m9mspN63v4lmRoUb6akEiIgkItGchbs/DDzc4dzX01x7ZprzN/V4w/qQaGZU1EFUCRARSYJWcPcBwcyoao6pGsygsmK279ZOeiLSsxQs+oBF82q55cKJ/PW542lsauX0Y4ZrcyQR6VEKFn3Ip48/gmOPGMw//XqdZkaJSI/S5kd9yPFff1SbI4lIItSz6EOizZGimVEDiozDB5Xy0JWfyG3DRKTgKVj0IdHmSA4YsK/NeXdPM/c9sznXTRORApdVsDCzj5lZWfj9mWZ2lZkdmmzTpDsaGpsowogvtVQJcxE5WNn2LB4EWs3sGOAugjIe9yXWKum2RfNqefr66cw6eSSlxcHHW1KkEuYicnCyDRZt4YrsC4F/dfe/BkYk1yw5GNFCvX1tbRQZtLQ5rW3Ogvue13RaEemWbIPFPjO7BLgc+FV4bkAyTZKeEJUwv2PuZACWrduu6bQi0m1ZFRIMd7j7MvC0u//EzMYCF7v7rUk3MFv9tZBgJio0KCKd6dFCgu7+irtfFQaKYUBFPgUKSW/5tWdxzoQj2o9VaFBEuiPb2VDLzGyImR0GPAf8PzO7LdmmSU+oGlJOZUVZ+7EKDYpId2Sbsxjq7ruAzwH/5e5TgU8l1yzpSQ2NTXyhdjRDy0s4fFApS196S4luEemSbINFiZmNAC5mf4JbCsSiebXc+vlJXHPueBr2NPPeB/uU6BaRLsk2WNxMsInR6+6+ysyOBjL+tjGzGWa2zsw2mNnCTq67yMw83FIVM/u0mT1rZi+Ff07Psp2SxvgbH+Fv/zvYpNDRQj0R6ZpsE9w/c/eT3P0r4fFGd7+os+eYWTFwJzATmABcEs6q6nhdBXA1sCJ2ugE4390nEkzX/XE27ZT0oh31SouDwlFaqCciXZFtgnu0mT1kZtvDrwfNbHSGp00BNoSBpRlYDMxOcd03gVuB9kF0d3/e3X8fHq4BBkblRqR79i/U8/aFenv3tWqhnohkJdthqB8AS4CR4dcvw3OdGQVsiR1vDc+1M7NTgDHuvrST17kIeM7dtf3bQYoW6v3wT06lpMhYtq5eC/VEJCvZ7mdR6e7x4PBDM/uLg3ljMysCbgO+2Mk1JxD0Os5J8/h8YD5AdXX1wTSnX1g0L1h3M/7GR2hpc1raggWZ2vdCRDLJtmfxrpldZmbF4ddlwLsZnrONoOBgZHR4LlIBnAgsM7M3gGnAkliSezTwEPDH7v56qjdw97vcvdbdaysrK7O8FYn2vQi3vdBCPRHJKNtg8acE02bfBt4CPk8nPYLQKmCcmY01s1JgDsFQFgDu/r67D3f3GnevAZ4BZrl7XVj+fCmw0N2f6soNSWbRvhcRLdQTkUyynQ31prvPcvdKd69y9wsIcgmdPacFWEAw5XYtcL+7rzGzm81sVoa3XAAcA3zdzF4Iv6qyaatkp6GxiUunHcXJY4ZSWlLEm+/u4eJFTyvZLSIpZVVIMOUTzTa7e94kClRIsHue37yTC//tf5k0eiirt73PpVOqueXCibluloj0kmwLCWab4E75HgfxXMkTc+56BoAXt74PKNktIqkdzB7c3euSSF5Zfu1ZnDV+/+QAJbtFJJVOexZmtpvUQcGAgYm0SHpV1ZByRh46ECP4oPfua+Pp1zNNdBOR/qbTnoW7V7j7kBRfFe5+MENYkkeCxXrVnBn2MLbvbtJCPRE5QLcT3PlGCe6Dox31RPqnHt0pT/q+qNBgWUnwI1FsKHchIu0ULATYX2iwubWN4iKj1aF+914VGhQRQMFCYqJCgz//yicYOrCEFRt3qNCgiADKWUgKyl+I9B/KWUi3RfmLkqJooyQ4fFApD135iRy3TERyRcFCPiLKX7S6Y0BLG7y7p5n7ntmc66aJSI5orYSk1NDYRBFGa2xNZlQKxIAVN5ytKrUi/Yh6FpLSonm1PH399HDf7v0/JhVlwf8vlPQW6V/Us5C09u/bvT/ZvbupBVDBQZH+Rj0L6VQ0nfaeL02l5vBD2ksNlxSZFu2J9CPqWUinon27AU4/Zjhv7thMEdDS5jS3tLLgvue5Y+5k5S9E+rhEexZmNsPM1pnZBjNb2Ml1F5mZR/tvh+euD5+3zszOTbKdkp2ol/Gfl59KscFv19Vr0Z5IP5HYojwzKwZeAz4NbCXYk/sSd3+lw3UVBPttlwILwj24JwA/AaYAI4HHgWPdvTXd+2lRXu/Roj2RviMfFuVNATa4+0Z3bwYWA7NTXPdN4FYgXoBoNrDY3ZvcfROwIXw9yQPLrz2L808a0Z6/KC02LdoT6eOSDBajgC2x463huXZmdgowxt2XdvW54fPnm1mdmdXV19f3TKslo6oh5QwZOKD9uLnVtWhPpI/L2WwoMysCbgO+1t3XcPe73L3W3WsrKyszP0F6TENjE0V24Dbs96zYTM3CpYxduFSVakX6mCSDxTZgTOx4dHguUgGcCCwzszeAacCSMMmd6bmSY+2L9iaNJCwhRbHBmMMGgsG3H36Vixc9raAh0kckGSxWAePMbKyZlQJzgCXRg+7+vrsPd/cad68BngFmuXtdeN0cMyszs7HAOGBlgm2VbqgaUk5FeUl7QZBWhy07PsQdfv78NlZu2sG0bz2R0zaKSM9ILFi4ewuwAHgMWAvc7+5rzOxmM5uV4blrgPuBV4BHgSs7mwkluRNftDfq0I+utWhzNDQl0gdoPwvpMTc89BL3hoUG4z9VwweX8u6eZi6dUs0tF07MVfNEJIV8mDor/UxDYxOXTTuKmSce2eF8M+5KgIsUMgUL6TGL5tVyywUn0urOZdM+Wk/KDKrDBLhWfYsUFg1DSaJueOgl7lu5mXQ/ZqXFxmt//5nebZSItNMwlOSFeAK8qqKs/Xw03fb8SSNz1DIR6Qr1LKTXRAnwVLT7nkhuqGcheaehsYnPnTKKaWMPaz9XUmTUHH6I8hgieU49C+l1mfIYql4r0nvUs5C8Fc9jDB9c2n5e1WtF8peChfS6aIrtGeOGc+4JR7ZPrY1Xr92+a69qS4nkEQULyal01WunfOsJVm7SLnwi+UI5C8m57bv2csvDa/n1y2+zN8UOfKDZUiJJUc5CCkbVkHIqykpoam2jtDjoZbSv+gZGDyvXbCmRHFOwkLwQJb1/ceUZjKsa3F6I0IGtO/ceUFvq2BsezmVTRfqlklw3QASCpHfk6MpBTD36cGaccCTXPbiabe99CNBezfb8SSPZvmsvC37yPHfMnayhKZFeoJyF5LXOVn0DXDZVZc9FDkZe5CzMbIaZrTOzDWa2MMXjXzazl8zsBTN70swmhOcHmNmPwsfWmtn1SbZT8le06vsPj61srycVFw1Njb/xkd5vnEg/kliwMLNi4E5gJjABuCQKBjH3uftEdz8Z+A5wW3j+j4Ayd58IfBy4wsxqkmqr5K9F82q57eKTGT1sIA4MKD4wYmghn0jvSLJnMQXY4O4b3b0ZWAzMjl/g7rtih4PggLzmIDMrAQYCzUD8WulnogT4f4cJ8IgW8on0jiQT3KOALbHjrcDUjheZ2ZXAXwGlwPTw9AMEgeUt4BDgL919R4rnzgfmA1RXV/dk2yXPdEyAb6zfQ2ss33bPis3cE+Y2bn98PVedPU4JcJEelFiC28w+D8xw9z8Lj+cBU919QZrr5wLnuvvlZnY68FXgi8AwYDkw0903pns/Jbj7l2wW8gF8bvIotr73oYKGSBr5kODeBoyJHY8Oz6WzGLgg/H4u8Ki773P37cBTQMabkf6js4V8cT9/fhsrN+1g2ree0DCVyEFIMlisAsaZ2VgzKwXmAEviF5jZuNjheUC0RHcz4ZCUmQ0CpgGvJthWKUCpFvJ1TIBH2hzVmxI5CInlLNy9xcwWAI8BxcD33X2Nmd0M1Ln7EmCBmX0K2AfsBC4Pn34n8AMzW0PwH8YfuPvqpNoqhSnVQr65U6q5evHzrN/e2L6Ir6Mov1FabDx53XTlNkSyoEV50udc8eM6KivK2dHYxMMvv502aFx0yigGDijm3pWbuXRKtZLi0i9lm7NQsJA+Kwoa8d5GNrQqXPoTBQuRmCt+XMegshJ2NDazfEMDrW2Zf+5Li43X/v4zvdA6kdzJh9lQInkjWgk+athA2twpK9n/o1+S5l9BVLBQM6hEFCykn4lmUD301dMZM2wgY4YNZMmCTx6wKjzy4HPb2mdQffvhVxU0pF/TMJQIBw5T/W59PelGqYoMnrn+bCXCpc/QMJRIF8SHqRzaF/p11HG9hoappL9QsBCJ6bjQD1KvDIdgvYaGqaS/0DCUSBrZrteI0zCVFBoNQ4kcpEXzarnlghNpdeeyaUex9Kr9ifB0M6jiw1Tx3oaGq6TQKViIZBAFjQkjh3B05SAum3ZU2hlUcfEihrc/sZ5VbxyY53jl9+8rgEjB0DCUSDd1Z5gqblzVYDbUN6rUiOSUVnCL9JJUZUWKjLTTbzuj/TektylYiORAx95GPGgMKDb2tWb3702JcuktSnCL5EDHpPiv/vyT7SvF4/uHF4XzcdNNy023nkN5DskV9SxEelHU89hY30hDYxOHDy6lYXdzp/tvxKXKc9x0/gRu+uUr3DF3MjjqjUiX5MUwlJnNAP6FYPOju9392x0e/zJwJdAKNALz3f2V8LGTgEXAEKANONXd0/53SsFCClW6RLkZZPPPMx5AAO3PIV2S82BhZsXAa8Cnga0E26xeEgWD8Joh7r4r/H4W8FV3n2FmJcBzwDx3f9HMDgfec/fWdO+nYCGFLlWivLTYaG71Ls+0ilPSXDqTDzmLKcAGd9/o7s3AYmB2/IIoUIQGsf/fwznAand/Mbzu3c4ChUhfkGo9R3x/8Y55jnT5jo7i6z2U+5DuSmwPbmAUsCV2vBWY2vEiM7sS+CugFJgenj4WcDN7DKgEFrv7dxJsq0heSbW/eKo8RzTbqtggmmgV/z4uSpoDXL34BTbUN3L74+s1XCVZSXIY6vPADHf/s/B4HjDV3RekuX4ucK67X25m1xDkMk4FPgCeAG509yc6PGc+MB+gurr642+++WYi9yKSb1Ilyrfu+BAIAk00jNWV4avLpqZOmiuA9G35kLM4DbjJ3c8Nj68HcPd/SHN9EbDT3Yea2RxgprtfHj72t8Bed//HdO+nnIXIfmmT5mQXPLS6vP/Ih2BRQpDgPhvYRpDgnuvua2LXjHP39eH35wN/5+61ZjaMoDdxBtAMPAp8z92Xpns/BQuRj+psdXlXA4gS5X1TtsEisZyFu7eY2QLgMYKps9939zVmdjNQ5+5LgAVm9ilgH7ATuDx87k4zu40gwDjwcGeBQkRSyzb3kc2sq58/vw2Aad96QqvL+yEtyhPpx7LpeXRGeY7Cl/NhqN6mYCFycDpbXZ5NYUTlOQqTgoWIHLR0ifJsq+oqz5H/8mFRnogUuHS7BbY5lBYHywI7WxyYakFgfOdALQ4sHOpZiEiX9ESeA4IaVsdUaugq1zQMJSKJ67SKbpaFEDuKD13Fq+iqom4yFCxEJCfS5TnSlSFJp8hg7pTq9iq6EPRGLjw5dTBRAOkeBQsRyalUw1VlJUU0tbQBdGnoKpV4MFEA6T4luEUkp1JV0X3oq6e37xw47ejDOfaIwUz72GEf2UEwG20O96zYjPuBifTbn1jPqjfS7zDY2bmO38t+6lmISM51tnd5vDfS3V5IfA1IS5vz07otByTXgU6Hu/pyD0XDUCJScOJDV1f8OPj3vGhebfv3E0cN/Ugw6W4iPVtFRnt5k3Rb2Bby0JeChYj0OamCSaoA0hM7DKbyscpBbGzYk1VvJAog+V4GRcFCRPqFdL2RjmtA4rOxUp2LD3cdrHjyPd1aknzpjShYiEi/1tkGUWMOOyTlplEdeytdLeOerfjCxFzP5FKwEBHpps5WqafrjcQDSneCS8d1Jamq+SYRTBQsRER6QKYtbDvLnRzsWhI4cCYX9HxvJC+ChZnNAP6FYPOju9392x0e/zLBXtutQCMw391fiT1eDbxCsD3rdzt7LwULEcmlVLmT+HBXVAalJ6YCRzr2Rm65cGKXXyPnwcLMigm2Vf00sJVg17tLOgSDIe6+K/x+FvBVd58Re/wBgr/LFQoWIlLIsp1j6n5IAAAH4UlEQVTJVVIEB5NnLyspYt0tM7O+PufbqgJTgA3uvjFs0GJgNkFPAYAoUIQGEQuyZnYBsAnYk2AbRUR6RXyL2+XXTQeCAHLZtKO6NJMrvq4kWvDuQPmAIs494UhuOO/4RNqfZLAYBWyJHW8Fpna8yMyuBP4KKAWmh+cGA9cR9EquSbCNIiI5kyqAQOr90qM8SareSDS0VVFWktgsqiSDRVbc/U7gTjObC9wIXA7cBHzP3RvN0heLMbP5wHyA6urq5BsrItIL4kGko3S9kftWbqY+wXpWSeYsTiNITJ8bHl8P4O7/kOb6ImCnuw81s+XAmPChQ4E24Ovufke691POQkSk6/IhZ7EKGGdmY4FtwBxgbvwCMxvn7uvDw/OA9QDu/snYNTcBjZ0FChERSVZiwcLdW8xsAfAYwdTZ77v7GjO7Gahz9yXAAjP7FLAP2EkwBCUiInlGi/JERPoxbX4kIiI9RsFCREQyUrAQEZGM+kzOwszqgTcP4iWGAw091Jx8oPvJb7qf/Naf7ucod6/M9AJ9JlgcLDOryybJUyh0P/lN95PfdD8fpWEoERHJSMFCREQyUrDY765cN6CH6X7ym+4nv+l+OlDOQkREMlLPQkREMur3wcLMZpjZOjPbYGYLc92erjKzMWb2WzN7xczWmNnV4fnDzOw3ZrY+/HNYrtvaFWZWbGbPm9mvwuOxZrYi/Jx+amaluW5jtszsUDN7wMxeNbO1ZnZaIX8+ZvaX4c/ay2b2EzMrL6TPx8y+b2bbzezl2LmUn4cFbg/va7WZnZK7lqeW5n7+Mfx5W21mD5nZobHHrg/vZ52ZnZvt+/TrYBFu/XonMBOYAFxiZhNy26ouawG+5u4TgGnAleE9LASecPdxwBPhcSG5GlgbO76VYI+TYwiKTn4pJ63qnn8BHnX344BJBPdVkJ+PmY0CrgJq3f1EgiKhcyisz+eHwIwO59J9HjOBceHXfODfe6mNXfFDPno/vwFOdPeTCLa3vh4g/N0wBzghfM6/hb8HM+rXwYLY1q/u3gxEW78WDHd/y92fC7/fTfCLaBTBffwovOxHwAW5aWHXmdlogpL1d4fHRrCL4gPhJQVzP2Y2FPgD4D8B3L3Z3d+jgD8fgmrVA82sBDgEeIsC+nzc/XfAjg6n030es4H/8sAzwKFmNqJ3WpqdVPfj7r9295bw8BlgdPj9bGCxuze5+yZgA8HvwYz6e7BItfXrqBy15aCZWQ0wGVgBHOHub4UPvQ0ckaNmdcc/A9cSbHoFcDjwXuyHv5A+p7FAPfCDcFjtbjMbRIF+Pu6+DfgusJkgSLwPPEvhfj6RdJ9HX/gd8afAI+H33b6f/h4s+oxw3/IHgb9w913xxzyY8lYQ097M7LPAdnd/Ntdt6SElwCnAv7v7ZGAPHYacCuzzGUbwv9OxwEhgEB8dAilohfR5ZGJmNxAMVd97sK/V34PFNvZv3wpBV21bjtrSbWY2gCBQ3OvuPw9PvxN1l8M/t+eqfV10OjDLzN4gGBacTjDmf2g47AGF9TltBba6+4rw+AGC4FGon8+ngE3uXu/u+4CfE3xmhfr5RNJ9HgX7O8LMvgh8FrjU96+R6Pb99Pdg0b71azh7Yw6wJMdt6pJwPP8/gbXuflvsoSXs33nwcuC/e7tt3eHu17v7aHevIfg8/sfdLwV+C3w+vKyQ7udtYIuZjQ9PnQ28QoF+PgTDT9PM7JDwZy+6n4L8fGLSfR5LgD8OZ0VNA96PDVflLTObQTCUO8vdP4g9tASYY2ZlFmx5PQ5YmdWLunu//gI+QzBb4HXghly3pxvtP4Ogy7waeCH8+gzBOP8TBPuaPw4cluu2duPezgR+FX5/dPhDvQH4GVCW6/Z14T5OBurCz+gXwLBC/nyAbwCvAi8DPwbKCunzAX5CkG/ZR9Dz+1K6zwMwghmTrwMvEcwCy/k9ZHE/GwhyE9HvhP+IXX9DeD/rgJnZvo9WcIuISEb9fRhKRESyoGAhIiIZKViIiEhGChYiIpKRgoWIiGSkYCGSgpk1hn/WmNncHn7tv+lw/L89+foiSVCwEOlcDdClYBFbyZzOAcHC3T/RxTaJ9DoFC5HOfRv4pJm9EO7jUBzuFbAq3CvgCgAzO9PMlpvZEoIVzZjZL8zs2XDvh/nhuW8TVGx9wczuDc9FvRgLX/tlM3vJzL4Qe+1ltn9PjHvD1dMivSbT/4BE+ruFwDXu/lmA8Jf+++5+qpmVAU+Z2a/Da08h2ENgU3j8p+6+w8wGAqvM7EF3X2hmC9z95BTv9TmC1d6TgOHhc34XPjaZYA+C3wNPEdRjerLnb1ckNfUsRLrmHIJaQS8QlII/nKC+DsDKWKAAuMrMXiTYT2BM7Lp0zgB+4u6t7v4O8P+BU2OvvdXd2wjKN9T0yN2IZEk9C5GuMeDP3f2xA06anUlQfjx+/CngNHf/wMyWAeUH8b5Nse9b0b9d6WXqWYh0bjdQETt+DPhKWBYeMzs23Myoo6HAzjBQHEew5W1kX/T8DpYDXwjzIpUEO+xlVxFUJGH634lI51YDreFw0g8J9taoAZ4Lk8z1pN5C9FHgy2a2lqC65zOxx+4CVpvZcx6UX488BJwGvEhQSfhad387DDYiOaWqsyIikpGGoUREJCMFCxERyUjBQkREMlKwEBGRjBQsREQkIwULERHJSMFCREQyUrAQEZGM/g9bKBVibTQl2gAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-4017ef4cceaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-a6aff6a6c25d>\u001b[0m in \u001b[0;36mtrain_setup\u001b[0;34m(net, lr, n_batches, batch_size, momentum, display_freq, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_force\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mteacher_force_upto\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdisplay_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-dd7c11c925df>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(net, opt, criterion, batch_size, device, teacher_force)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GM1Tj20omMi1"
      },
      "source": [
        "### Training with Attention "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lxFLBqW1Ip4v"
      },
      "outputs": [],
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "colab_type": "code",
        "id": "tdRpJUXNIwuv",
        "outputId": "6e8ed733-4b95-4eae-ac09-be4f6a905d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.1429685652256012\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuYVPWd5/H3h0bAKBjUxlFAQcVrLmo6mIyXeEEFzYCJ+yRodHRMHjQbYhIzoxDc2Vmi4yU7eWISdwPrmosJkotrpjNKSLwlkl2FRlEDDtAgUYhKi46XqEDDd/+oU3i66O6qgjpV1V2f1/PU03V+55yqb5/urm//Luf3U0RgZmbWmwG1DsDMzOqfk4WZmRXlZGFmZkU5WZiZWVFOFmZmVpSThZmZFZVpspA0UdJKSe2SZnSz/zJJHZKWJY/PpfZtS5W3ZhmnmZn1TlndZyGpCVgFnAWsB5YAF0bEitQxlwEtETG9m/PfjIi9MwnOzMzKkmXNYjzQHhFrI2ILMB+YkuH7mZlZRgZm+NojgedT2+uBE7s57gJJp5KrhXwlIvLnDJHUBnQCN0XELwtPlDQNmAaw1157feioo46qZPxmZv3e0qVLX46I5mLHZZksSvEr4K6I2CzpCuCHwBnJvkMiYoOkQ4EHJT0dEWvSJ0fEXGAuQEtLS7S1tVUzdjOzPk/Sn0o5LstmqA3A6NT2qKRsh4jYFBGbk83bgQ+l9m1Ivq4FHgaOzzBWMzPrRZbJYgkwTtJYSYOAqUCXUU2SDkxtTgaeScqHSxqcPN8fOAlYgZmZ1URmzVAR0SlpOrAQaALuiIjlkmYDbRHRClwlaTK5folXgMuS048G5kjaTi6h3ZQeRWVmZtWV2dDZanOfhZlZ+SQtjYiWYsf5Dm4zMyvKyQLY+Po7fGrO/2PjG+/UOhQzs7rkZAF8+4HVLFn3Ct++f3WtQzEzq0u1vs+ipo68bgGbO7fv2P7xY8/x48eeY/DAAay8flINIzMzqy8NXbN45JrTmXzcQTu2h+wxgCnHHcQj155ew6jMzOpPQyeLEcOGMHTwu5WrzZ3bGTp4ICOGDqlhVGZm9aehkwXAy29u3vH8k8ePoiO1bWZmOQ2fLG676ITUVjDnkqLDjc3MGo47uFMd3Hc/voG7H9/gDm4zswINXbPo6e71/nJXu5lZpTR0slh07RmMGr5nl7Ix+72HRTPO6OEMM7PG1NDJYsSwnUc9bdseHg1lZlagofssAI49aBgCBkicckQzHZ7yw8xsJw2fLOZc0sJVdz3BU+v/g+vPf1+twzEzq0sN3QyVtz2CP//H255I0MysB04WwMoX32DLtvBEgmZmPWjoZihPJGhmVppMaxaSJkpaKald0oxu9l8mqUPSsuTxudS+SyWtTh6XZhFffiLBJuW2Bw+UJxI0M+tGZjULSU3AbcBZwHpgiaTWbtbS/mlETC84d1/gvwItQABLk3NfrWSM+YkEtyX34G3uDE8kaGbWjSxrFuOB9ohYGxFbgPnAlBLPPQf4bUS8kiSI3wITKx3gkdct4CePPdel7MePPceR1y2o9FuZmfVpWSaLkcDzqe31SVmhCyQ9JekXkkaXc66kaZLaJLV1dHSUHWC+GWrggFw71JCBXs/CzKw7tR4N9StgTER8gFzt4YflnBwRcyOiJSJampuby37zfDNU5/ZcO9Q7Xs/CzKxbWSaLDcDo1PaopGyHiNgUEfkFJG4HPlTquZXy8pubOWDYYCA3L5TXszAz21mWyWIJME7SWEmDgKlAa/oASQemNicDzyTPFwJnSxouaThwdlJWUUdet4CFy1/ipddzCWLdprdYuPwl91mYmRXILFlERCcwndyH/DPAzyJiuaTZkiYnh10labmkJ4GrgMuSc18Bvk4u4SwBZidlFZXvsxiUjJ0d7D4LM7NuZXpTXkTcB9xXUPaPqeczgZk9nHsHcEeW8eX7LLYmY2c3d25noOQ+CzOzArXu4K65l9/czISjD9ixvXhdxSswZmZ9XkNP9wHw8MqOLlN+PP/q24yZca+n/DAzS2n4msUj15zOx454d9jtkD3cb2FmVqjhk8WIYUMYOiRXwRo4QGz2vRZmZjtp+GYogNff3grAF884nI43t3i1PDOzAg1fswD475/6IAD3PLGBq848nDmXtNQ4IjOz+uJkAQxuagLgT5ve8gJIZmbdaPhmqPQCSIEXQDIz607D1yweueZ0Jn/woB3bXgDJzGxnDZ8s0qOhwAsgmZl1p+GThRdAMjMrruGTRX4ywTw3Q5mZ7azhk0V+MsE8N0OZme2s4ZOFm6HMzIpr+GSRb4ZKluH23FBmZt1o+GSRb4baHiDw3FBmZt3INFlImihppaR2STN6Oe4CSSGpJdkeI+ltScuSx/eyjPPlNzczdr+9GDFsMJ858RCvw21mViCzO7glNQG3AWcB64ElklojYkXBcUOBLwGPFbzEmog4Lqv40uZc0sKX5z/BvU+/wFVnHu5ahZlZgSxrFuOB9ohYGxFbgPnAlG6O+zpwM1DTqV6feeF1tm4Lzw1lZtaNLOeGGgk8n9peD5yYPkDSCcDoiLhX0j8UnD9W0hPA68B1EfFI4RtImgZMAzj44IN3Kcj03FDguaHMzLpTsw5uSQOAbwJf7Wb3C8DBEXE8cDUwT9KwwoMiYm5EtERES3Nz804vUor8aKiByXAoj4YyM9tZlsliAzA6tT0qKcsbCrwPeFjSOuAjQKuklojYHBGbACJiKbAGOCKLIPOjoTq3BwDvbPVoKDOzQlkmiyXAOEljJQ0CpgKt+Z0R8VpE7B8RYyJiDPAoMDki2iQ1Jx3kSDoUGAeszSrQl9/czP57DwLgsOa9PBrKzKxAZn0WEdEpaTqwEGgC7oiI5ZJmA20R0drL6acCsyVtBbYDV0bEK1nEWdhnsabjL6zp+AtHXrfAfRZmZglFRK1jqIiWlpZoa2sr+7yNr7/D9fc9w31P/ZnO7TCoSUx6/4HMOu9oN0WZWb8naWlEFF1L2ndw7+izyG1v2eaJBM3MCjV8svBEgmZmxTV8ssgPnR00MHcpBJxz7AEeOmtmltLwySLfDLU1aYcKYG3HX9wMZWaW0vDJAuCuxc+R7uZfvfFNxsy4101RZmYJJwvg0Zlncu77/mrHtpdWNTPrysmCXFPUe98zaMe2l1Y1M+vKyYLciKh5iz0iysysJ04WQE/3JfaP2xXNzHafkwWw6NrTGbPfe7qUjdnvPSxyn4WZGeBkAcAptzzEuk1vdSlbt+ktTrn5oRpFZGZWX5wsyN2Y91f7DN6xPUBw4D5DPBrKzCzhZEFuNNSZRx2wY3t7wJlHjfBoKDOzhJMFnh/KzKwYJwvenR9KyfYA4ZvyzMxSMlv8qC855ZaHuiyAtD3gX5f9mV//8UUvgGRmhmsWwLsd3AP0btmeewxwzcLMLJFpspA0UdJKSe2SZvRy3AWSQlJLqmxmct5KSedkGeeIYUPY+Ppmtqfuwnt763bG3/CA+y3MzMiwGUpSE3AbcBawHlgiqTUiVhQcNxT4EvBYquwYYCpwLHAQcL+kIyJiW1bx9sR3cZuZZVuzGA+0R8TaiNgCzAemdHPc14GbgXdSZVOA+RGxOSKeBdqT18vMwAFukTMz60mWn5AjgedT2+uTsh0knQCMjoh7yz03OX+apDZJbR0dHZWJ2szMdlKzf6clDQC+CXx1V18jIuZGREtEtDQ3N1cuODMz6yLLZLEBGJ3aHpWU5Q0F3gc8LGkd8BGgNenkLnZuxS269nT23KOpS9l79mjyZIJmZmSbLJYA4ySNlTSIXId1a35nRLwWEftHxJiIGAM8CkyOiLbkuKmSBksaC4wDFmcYK6fc8hBvb+3af/7W1m2eTNDMjAyTRUR0AtOBhcAzwM8iYrmk2ZImFzl3OfAzYAXwa+ALWY+EKpxMEGDIQPleCzMzQNHTyj99TEtLS7S1te3y+Udet6DLXdxpgwcO8J3cZtYvSVoaES3FjvN40cQj1/Rcg+gpiZiZNQoni8SIYUO6TPeRtkdTDzvMzBqEk0XKqeP2pzAtCPjDjDNqEY6ZWd1wskh5eNXLO03vEcD4Gx6oRThmZnXDySLlvqtO7nHfmBmFN5mbmTUOJ4uUYw7ap8d97rcws0bmZFEiycnCzBqXk0WJtnj4rJk1MCeLAr01N3khJDNrVE4WBf5wbc/DZH1znpk1KieLAiOGDal1CGZmdcfJohu99WW7KcrMGpGTRTcem3lmj/vcFGVmjcjJohtuijIz68rJYhf4bm4zazROFj3obeoPM7NGk2mykDRR0kpJ7ZJmdLP/SklPS1omaZGkY5LyMZLeTsqXSfpelnF2p7epP8Ad3WbWWAZm9cKSmoDbgLOA9cASSa0RsSJ12LyI+F5y/GTgm8DEZN+aiDguq/hKsd9eg9j0ly3d7nNHt5k1kpJqFpIOkzQ4eX6apKskvbfIaeOB9ohYGxFbgPnAlPQBEfF6anMv2GmG8Jpa+l/O6nW/axdm1ihKbYa6G9gm6XBgLjAamFfknJHA86nt9UlZF5K+IGkNcAtwVWrXWElPSPqdpFO6ewNJ0yS1SWrr6Ogo8VspzwdGDutxn2sXZtYoSk0W2yOiE/gE8J2I+AfgwEoEEBG3RcRhwLXAdUnxC8DBEXE8cDUwT9JOn9oRMTciWiKipbm5uRLh7KT1i93mKTOzhlJqstgq6ULgUuDfkrI9ipyzgVwNJG9UUtaT+cD5ABGxOSI2Jc+XAmuAI0qMtao8jNbMGkGpyeLvgI8CN0TEs5LGAncWOWcJME7SWEmDgKlAa/oASeNSm+cBq5Py5qSDHEmHAuOAtSXGWnGLv9bzHd3gvgsz6/9KGg2VjGC6CkDScGBoRNxc5JxOSdOBhUATcEdELJc0G2iLiFZguqQJwFbgVXI1F4BTgdmStgLbgSsj4pXyv73KKHZHt/suzKy/U0TxAUiSHgYmk0suS4GNwB8i4upMoytDS0tLtLW1Zfb6V9zZxsLlL/V6zLqbzsvs/c3MsiBpaUS0FDuu1GaofZJhrp8EfhQRJwITdifAvmbOJS2MGDq412Pcf2Fm/VWpyWKgpAOBT/FuB3fDWTyrofKjmdkOpSaL2eT6HtZExJKk03l1dmHVr2JNTa5dmFl/VFKyiIifR8QHIuLzyfbaiLgg29Dq12lH7N/rficMM+tvSp3uY5SkeyRtTB53SxqVdXD16geXn1jrEMzMqqrUZqjvk7tH4qDk8aukrGGdc+wBve537cLM+pNSk0VzRHw/IjqTxw+AbObX6CPmXNLCoIG9Xz4nDDPrL0pNFpskXSypKXlcDGzKMrC+YNX1k4oe44RhZv1BqcnicnLDZl8kN8nffwIuyyimPqWUG/GcMMysryt1NNSfImJyRDRHxIiIOB9o2NFQhYrdrAdOGGbWt+3Osqp1M9VHrS2eNaFo/wU4YZhZ37U7yUIVi6IfWHX9JFTCFXHCMLO+aHeSRV0tgVoPnr3xPDdJmVm/1GuykPSGpNe7ebxB7n4LK7B41oSSaxiL2rNZCtbMrNJ6TRYRMTQihnXzGBoRJa2F0YhKrWFcfPti/u2p3hYPNDOrD7vTDGW9WDxrQkkJY/q8ZW6WMrO652SRocWzJhSdFiTPzVJmVs8yTRaSJkpaKald0oxu9l8p6WlJyyQtknRMat/M5LyVks7JMs4szbmkpeQV9C6+fTHzHluXbUBmZrsgs2QhqQm4DZgEHANcmE4GiXkR8f6IOA64Bfhmcu4xwFTgWGAi8D+S1+uzSq1hfO2e5a5lmFndybJmMR5oT9a+2ALMB6akD0iWas3bi3eH404B5kfE5oh4FmhPXq/PytcwShkpBblaxpzfNeT6UmZWh7JMFiOB51Pb65OyLiR9QdIacjWLq8o8d5qkNkltHR194z/xUkdKAdy4YJVrGWZWF2rewR0Rt0XEYcC1wHVlnjs3IloioqW5ue/MmL541oSS+zEgV8v4l988k2FEZma9yzJZbABGp7ZHJWU9mQ+cv4vn9knlNEt958G1jJlxr5OGmdVElsliCTBO0lhJg8h1WLemD5A0LrV5HpBvpG8FpkoaLGksMA5YnGGsNfPsjeeV3PkN7yaNU25+kI1vvJNhZGZm78rsLuyI6JQ0HVgINAF3RMRySbOBtohoBaZLmgBsBV4FLk3OXS7pZ8AKoBP4QkRsyyrWWptzSQsAY2feS5Q449bzr77N+BseYPTwPbn7P/81I4YOyTBCM2t0ilI/nepcS0tLtLW11TqMitiVO7pnTjqCKz42rviBZmYpkpZGREux42rewW07W3fTeSWtj5GWHznl4bZmlgXXLOrcrs4b5ZqGmZWi1JqFk0UfsatJ458/cSwXnTimssGYWb/hZNFPOWmYWSU5WfRzThpmVglOFg3CScPMdoeTRYPZlaQh4M7Pjefkw/vOVClmVlkeOttg1t1U3p3gkJvi1/NOmVkpnCz6kfw06KXOapuXn0LE64GbWU/cDNWPjb/hfja+sbmscwY3iXumn8QxB+6TUVRmVk/cDGU7pkIvp6axeVtw7q2LvLyrmXXhmkUDueLONhYuf6msc+770smuZZj1Y65Z2E7yfRrlzDvlWoaZgWsWDa3c4bauZZj1P65ZWFGuZZhZqVyzMMC1DLNGVRc1C0kTJa2U1C5pRjf7r5a0QtJTkh6QdEhq3zZJy5JHa+G5Vlnljpo699ZFvi/DrIFkVrOQ1ASsAs4C1pNbk/vCiFiROuZ04LGIeEvS54HTIuLTyb43I2LvUt/PNYvKKbeWsXjWmV7W1ayPqoeaxXigPSLWRsQWYD4wJX1ARDwUEW8lm48CozKMx0pU7tQh4294gEXtHRlGZGa1lmWyGAk8n9pen5T15LPAgtT2EEltkh6VdH53J0ialhzT1tHhD6tKyg+zlUo7/uLbFzN2F2fANbP6VxejoSRdDLQA30gVH5JUjS4CviXpsMLzImJuRLREREtzs2dOzcKzN5belxHkmrBcyzDrf7JMFhuA0antUUlZF5ImALOAyRGxYyKjiNiQfF0LPAwcn2Gs1ov8tCGluvj2xR5ia9bPZJkslgDjJI2VNAiYCnQZ1STpeGAOuUSxMVU+XNLg5Pn+wEnACqymyrkv42v3LGfMjHvZ+MY7GUdlZtWQWbKIiE5gOrAQeAb4WUQslzRb0uTksG8AewM/LxgiezTQJulJ4CHgpvQoKqudVddPKquWMf6GBzzE1qwf8E15tsuOuG4BWzq3l3x8OUnGzKqjHobOWj+36vpJZQ2x9QJLZn2Xk4XtlnKH2E6ft4w5v1udbVBmVnFOFlYR5QyxvXHBKg+xNetjnCysYjzE1qz/crKwiitnUsL8ENsVL7yWcVRmtjucLCwT5dYyvFaGWX1zsrBM7cqNfK5lmNUfJwvLXLk38p176yKPmDKrM04WVjXlDLHNj5ia+K3fe8oQszrgO7it6q64s42Fy1/a5fP/+RPHctGJYyoXkFkDK/UObicLq5mxM+9ld3/9Zk46gis+Nq4yAZk1ICcL6xPG33A/G9/YXPzAEgxqEr+cfhLHHLhPRV7PrBE4WVifUu6636Vwc5VZcU4W1ufsbl9Gb5w4zLrnZGF9ViX6MnozuEnc4+YqM8DJwvqZLGsd7iS3RuZkYf1aFn0c4FqHNZ66SBaSJgK3Ak3A7RFxU8H+q4HPAZ1AB3B5RPwp2XcpcF1y6PUR8cPe3svJonFl2WzlWof1dzVPFpKagFXAWcB6YAlwYXotbUmnA49FxFuSPg+cFhGflrQv0Aa0AAEsBT4UEa/29H5OFgaVHYrbHXeUW39TD8nio8A/RcQ5yfZMgIi4sYfjjwe+GxEnSbqQXOK4Itk3B3g4Iu7q6f2cLKxQ1onD93VYf1BqshiYYQwjgedT2+uBE3s5/rPAgl7OHVl4gqRpwDSAgw8+eHditX5o8awJXbYr3c+xZVtw7q2LdmwftM8Qfjn9JEYMHVLR9zGrB1kmi5JJuphck9PHyjkvIuYCcyFXs8ggNOtH0jPfZjG66s+vvcP4Gx7Yse2ah/UnWSaLDcDo1PaopKwLSROAWcDHImJz6tzTCs59OJMorSHNuaRrrTuL0VWFNQ8Bd35uPCcf3lzx9zLLWpZ9FgPJdXCfSe7DfwlwUUQsTx1zPPALYGJErE6V70uuU/uEpOhxch3cr/T0fu6zsErJ8p6OQu4wt1qreQd3EsS5wLfIDZ29IyJukDQbaIuIVkn3A+8HXkhOeS4iJifnXg58LSm/ISK+39t7OVlYVrLuKE/zfR5WbXWRLKrJycKqJevpSAq59mFZcrIwq5Ks7ibviWsfVklOFmY1Uu3kAb7T3Hadk4VZnah2s1Wem6+sFE4WZnWqmqOtCn3xjEP56tlH1+S9rT45WZj1IbVouspzE1Zjc7Iw68NqWfsA30DYSJwszPqZWtY+8lwL6X+cLMwaQD0kEPBw3r7MycKsAVXzbvNSuDmr/jlZmNkO9VIDSfPQ3vrgZGFmPap1B3pvXBupLicLMytbrW4gLJU72CvPycLMKqKeayFpvuFw1zhZmFnm6rEvpCffveg4Pv6BnVZnbnhOFmZWM/XenFWokftJnCzMrO70lSat7vTX0Vt1kSwkTQRuJbdS3u0RcVPB/lPJraT3AWBqRPwitW8b8HSyuWMFvZ44WZj1bUdct4AtndtrHcYu66t9JjVPFpKayK3BfRawntwa3BdGxIrUMWOAYcDfA60FyeLNiNi71PdzsjDrn/pybSStXpu6Sk0WAzOMYTzQHhFrk4DmA1OAHckiItYl+/ruvxNmlqk5l/T+OdZXOtkDuPj2xUWPq9eO+CyTxUjg+dT2euDEMs4fIqkN6ARuiohfFh4gaRowDeDggw/ejVDNrK9ad9N5Pe6rt+lPSjF93jKmz1vW6zG1aPLKMlnsrkMiYoOkQ4EHJT0dEWvSB0TEXGAu5JqhahGkmdWvxbMm9Lq/r43ayvvOg2v5zoNru5RlXSPJMllsAEantkclZSWJiA3J17WSHgaOB9b0epKZWRmevbHnWgn0rf6Sr/z0yT6bLJYA4ySNJZckpgIXlXKipOHAWxGxWdL+wEnALZlFambWjWL9JVA/fSZbt8WOWHprmttVmSWLiOiUNB1YSG7o7B0RsVzSbKAtIlolfRi4BxgO/I2k/xYRxwJHA3OSju8B5PosVvTwVmZmNVPsg7maTV0CvnPRcdm8tm/KMzOrrUrdY7JHk1h9w7llnVMPQ2fNzKwEq66fVNJxxZq8Ordn98+/k4WZWR+RRV9EqQbU7J3NzKzPcLIwM7OinCzMzKwoJwszMyvKycLMzIpysjAzs6L6zU15kjqAP+3GS+wPvFyhcCrJcZXHcZXHcZWnP8Z1SEQUXWSj3ySL3SWprZS7GKvNcZXHcZXHcZWnkeNyM5SZmRXlZGFmZkU5Wbxrbq0D6IHjKo/jKo/jKk/DxuU+CzMzK8o1CzMzK8rJwszMimr4ZCFpoqSVktolzajye4+W9JCkFZKWS/pSUv5PkjZIWpY8zk2dMzOJdaWkczKMbZ2kp5P3b0vK9pX0W0mrk6/Dk3JJ+nYS11OSTsgopiNT12SZpNclfblW10vSHZI2SvpjqqzsayTp0uT41ZIuzSiub0j69+S975H03qR8jKS3U9fue6lzPpT8DrQnsSuDuMr+2VX6b7aHuH6aimmdpGVJeTWvV0+fD7X5HYuIhn2QW+51DXAoMAh4Ejimiu9/IHBC8nwosAo4Bvgn4O+7Of6YJMbBwNgk9qaMYlsH7F9QdgswI3k+A7g5eX4usIDcqo4fAR6r0s/uReCQWl0v4FTgBOCPu3qNgH2BtcnX4cnz4RnEdTYwMHl+cyquMenjCl5ncRKrktgnZRBXWT+7LP5mu4urYP+/AP9Yg+vV0+dDTX7HGr1mMR5oj4i1EbEFmA9MqdabR8QLEfF48vwN4BlgZC+nTAHmR8TmiHgWaCf3PVTLFOCHyfMfAuenyn8UOY8C75V0YMaxnAmsiYje7trP9HpFxO+BV7p5z3Ku0TnAbyPilYh4FfgtMLHScUXEbyKiM9l8FBjV22sksQ2LiEcj94nzo9T3UrG4etHTz67if7O9xZXUDj4F3NXba2R0vXr6fKjJ71ijJ4uRwPOp7fX0/mGdGUljgOOBx5Ki6UlV8o58NZPqxhvAbyQtlTQtKTsgIl5Inr8IHFCDuPKm0vUPuNbXK6/ca1SLGC8n9x9o3lhJT0j6naRTkrKRSSzViKucn121r9cpwEsRsTpVVvXrVfD5UJPfsUZPFnVB0t7A3cCXI+J14H8ChwHHAS+QqwZX28kRcQIwCfiCpFPTO5P/nmoy7lrSIGAy8POkqB6u105qeY16ImkW0An8JCl6ATg4Io4HrgbmSRpWxZDq8meXciFd/ymp+vXq5vNhh2r+jjV6stgAjE5tj0rKqkbSHuR+EX4SEf8HICJeiohtEbEd+F+823RStXgjYkPydSNwTxLDS/nmpeTrxmrHlZgEPB4RLyUx1vx6pZR7jaoWo6TLgI8Dn0k+ZEiaeTYlz5eS6w84Iokh3VSVSVy78LOr5vUaCHwS+Gkq3qper+4+H6jR71ijJ4slwDhJY5P/VqcCrdV686Q99H8Dz0TEN1Pl6fb+TwD5URqtwFRJgyWNBcaR61SrdFx7SRqaf06uc/SPyfvnR1JcCvxrKq6/TUZjfAR4LVVNzkKX//Zqfb0KlHuNFgJnSxqeNMGcnZRVlKSJwDXA5Ih4K1XeLKkpeX4ouWu0NontdUkfSX5P/zb1vVQyrnJ/dtX8m50A/HtE7Ghequb16unzgVr9ju1Ob31/eJAbQbCK3H8Is6r83ieTq0I+BSxLHucCdwJPJ+WtwIGpc2Ylsa5kN0db9BLXoeRGmTwJLM9fF2A/4AFgNXA/sG9SLuC2JK6ngZYMr9lewCZgn1RZTa4XuYT1ArCVXDvwZ3flGpHrQ2hPHn+XUVzt5Nqt879n30uOvSD5GS8DHgf+JvU6LeQ+vNcA3yWZ8aHCcZX9s6v032x3cSXlPwCuLDi2mterp8+HmvyOeboPMzMrqtGboczMrAROFmZmVpSThZmZFeVkYWZmRTlZmJlZUU4WZt2Q9GbydYykiyrHq9LhAAAB4klEQVT82l8r2P6/lXx9syw4WZj1bgxQVrJI7vztTZdkERF/XWZMZlXnZGHWu5uAU5Rbu+ArkpqUWxtiSTL53RUAkk6T9IikVmBFUvbLZCLG5fnJGCXdBOyZvN5PkrJ8LUbJa/9RuXURPp167Ycl/UK5NSl+ktzda1Y1xf4DMmt0M8itt/BxgORD/7WI+LCkwcAfJP0mOfYE4H2Rm1Ib4PKIeEXSnsASSXdHxAxJ0yPiuG7e65PkJtT7ILB/cs7vk33HA8cCfwb+AJwELKr8t2vWPdcszMpzNrn5d5aRmy56P3LzAwEsTiUKgKskPUlu/YjRqeN6cjJwV+Qm1nsJ+B3w4dRrr4/chHvLyDWPmVWNaxZm5RHwxYjoMhGbpNOAvxRsTwA+GhFvSXoYGLIb77s59Xwb/tu1KnPNwqx3b5Bb0jJvIfD5ZOpoJB2RzMxbaB/g1SRRHEVumcu8rfnzCzwCfDrpF2kmt9xn1rPkmpXE/52Y9e4pYFvSnPQD4FZyTUCPJ53MHXS/fOavgSslPUNu1tRHU/vmAk9JejwiPpMqvwf4KLnZfgO4JiJeTJKNWU151lkzMyvKzVBmZlaUk4WZmRXlZGFmZkU5WZiZWVFOFmZmVpSThZmZFeVkYWZmRf1/3IMHwxEEn7EAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoderAttention_Type2. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ]
        }
      ],
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "05F1-FwX6YVZ"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "v3TWC7zhAn3z"
      },
      "outputs": [],
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    hindi_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bT8bibYl7CgX"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "dy1bQiORAs5o",
        "outputId": "452fb821-0d7a-4dd9-e964-e4f4d5597ae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  21.70477133977133\n"
          ]
        }
      ],
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "# accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "# print('Acurracy with attention', accuracy_attn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "colab_type": "code",
        "id": "1kNnqWIgjU-t",
        "outputId": "9859cfaa-9ab4-4581-cb84-6d279c289660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SOURABH - रॏलॏलॏ\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'रॏलॏलॏ'"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test(net,'SOURABH')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0721_EncoderDecoderArchitecture.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
